{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gqt11Y_RYxU"
      },
      "source": [
        "# Setting up the environment. PLEASE WAIT ðŸ™ƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHmGnnTZL6os"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!pip install rembg[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX3LsFFPKSwo"
      },
      "outputs": [],
      "source": [
        "! wget -c \"https://github.com/Kitware/CMake/releases/download/v3.19.6/cmake-3.19.6.tar.gz\"\n",
        "! tar xf cmake-3.19.6.tar.gz\n",
        "! cd cmake-3.19.6 && ./configure && make && sudo make install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51QJAhPOK9cK"
      },
      "outputs": [],
      "source": [
        "# Install library\n",
        "! sudo apt-get --assume-yes update\n",
        "! sudo apt-get --assume-yes install build-essential\n",
        "# OpenCV\n",
        "! sudo apt-get --assume-yes install libopencv-dev\n",
        "# General dependencies\n",
        "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev\n",
        "# Remaining dependencies, 14.04\n",
        "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "# Python3 libs\n",
        "! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential\n",
        "! sudo apt-get --assume-yes install python3-pip\n",
        "! sudo -H pip3 install --upgrade numpy protobuf opencv-python\n",
        "# OpenCL Generic\n",
        "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
        "! sudo apt-get --assume-yes install libviennacl-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7tqqDLHLNDr",
        "outputId": "cf664547-56a1-45cc-d4f2-e7c3d42e9139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1.7.0\n"
          ]
        }
      ],
      "source": [
        "ver_openpose = \"v1.7.0\"\n",
        "! echo $ver_openpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b11_hkSgLDl5"
      },
      "outputs": [],
      "source": [
        "! git clone  --depth 1 -b \"$ver_openpose\" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-XyxfV8Q-DE"
      },
      "outputs": [],
      "source": [
        "# manually downloading openpose models\n",
        "%%bash\n",
        "gdown 1QCSxJZpnWvM00hx49CJ2zky7PWGzpcEh\n",
        "unzip models.zip\n",
        "mv /content/models/face/pose_iter_116000.caffemodel /content/openpose/models/face/pose_iter_116000.caffemodel\n",
        "mv /content/models/hand/pose_iter_102000.caffemodel /content/openpose/models/hand/pose_iter_102000.caffemodel\n",
        "mv /content/models/pose/body_25/pose_iter_584000.caffemodel /content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\n",
        "mv /content/models/pose/coco/pose_iter_440000.caffemodel /content/openpose/models/pose/coco/pose_iter_440000.caffemodel\n",
        "mv /content/models/pose/mpi/pose_iter_160000.caffemodel /content/openpose/models/pose/mpi/pose_iter_160000.caffemodel\n",
        "rm -rf models\n",
        "rm models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bs-zIObzQLYj"
      },
      "outputs": [],
      "source": [
        "! cd openpose && mkdir build && cd build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7oHh2vQqHv"
      },
      "outputs": [],
      "source": [
        "! cd openpose/build && cmake -DUSE_CUDNN=OFF -DBUILD_PYTHON=ON .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iBvxsDM-EYJk"
      },
      "outputs": [],
      "source": [
        "# ! cd openpose/build && cmake .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEAY8VW0RzD0"
      },
      "outputs": [],
      "source": [
        "! cd openpose/build && make -j`nproc`\n",
        "! cd openpose && mkdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60nEQBKefg3f"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pyngrok==4.1.1\n",
        "!ngrok authtoken <your_ngrok_authtoken>\n",
        "# get it from here https://dashboard.ngrok.com/get-started/your-authtoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo-q2Q-XMFen"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%cd /content/\n",
        "!rm -rf clothes-virtual-try-on\n",
        "!git clone https://github.com/practice404/clothes-virtual-try-on.git\n",
        "os.makedirs(\"/content/clothes-virtual-try-on/checkpoints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnud6ptA9ZwL"
      },
      "outputs": [],
      "source": [
        "!gdown --id 18q4lS7cNt1_X8ewCgya1fq0dSk93jTL6 --output /content/clothes-virtual-try-on/checkpoints/alias_final.pth\n",
        "!gdown --id 1uDRPY8gh9sHb3UDonq6ZrINqDOd7pmTz --output /content/clothes-virtual-try-on/checkpoints/gmm_final.pth\n",
        "!gdown --id 1d7lZNLh51Qt5Mi1lXqyi6Asb2ncLrEdC --output /content/clothes-virtual-try-on/checkpoints/seg_final.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWPkjShFMK82"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1ysEoAJNxou7RNuT9iKOxRhjVRNY5RLjx --output /content/clothes-virtual-try-on/cloth_segm_u2net_latest.pth --no-cookies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9MhYntvMP84"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz9LOnvyMWEJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PeikeLi/Self-Correction-Human-Parsing\n",
        "%cd Self-Correction-Human-Parsing\n",
        "!mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2k0DLCsMaG0"
      },
      "outputs": [],
      "source": [
        "# downloading LIP dataset model\n",
        "!gdown --id 1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
        "!mv /content/Self-Correction-Human-Parsing/exp-schp-201908261155-lip.pth /content/Self-Correction-Human-Parsing/checkpoints/final.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y4f3VRyMd9Z"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k2dVj4vMhwA"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n",
        "conda install --channel defaults conda python=3.8 --yes\n",
        "conda update --channel defaults --all --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "I6entwp3MliV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.6/site-packages\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cseosViyMtYx"
      },
      "outputs": [],
      "source": [
        "!conda install --channel conda-forge featuretools --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEnK6NI6M0cz"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python torchgeometry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkySNWttHdW2"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wvtaXujRhNp"
      },
      "source": [
        "# Welcome to Virtual-Cloth-Assistant\n",
        "\n",
        "> It'll take some extra time in first execution for setting up and downloading of model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RwcUm39LM8H0"
      },
      "outputs": [],
      "source": [
        "def make_dir():\n",
        "  os.system(\"cd /content/ && mkdir inputs && cd inputs && mkdir test && cd test && mkdir cloth cloth-mask image image-parse openpose-img openpose-json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9jGRSFuEM9-q",
        "outputId": "1a371720-c1ad-4910-f931-1536df397f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://f067-34-16-178-13.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "data recieved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2023 08:13:41] \"POST /api/transform HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, send_file, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return jsonify(\"hello world\");\n",
        "\n",
        "@app.route(\"/api/transform\", methods=['POST'])\n",
        "def begin():\n",
        "  make_dir()\n",
        "  print(\"data recieved\")\n",
        "  cloth = request.files['cloth']\n",
        "  model = request.files['model']\n",
        "\n",
        "  cloth = Image.open(cloth.stream)\n",
        "  model = Image.open(model.stream)\n",
        "\n",
        "  cloth.save(\"/content/inputs/test/cloth/cloth.jpg\")\n",
        "  model.save(\"/content/inputs/test/image/model.jpg\")\n",
        "\n",
        "  # running script to compute the predictions\n",
        "  os.system(\"python /content/clothes-virtual-try-on/run.py\")\n",
        "\n",
        "  # loading output\n",
        "  op = os.listdir(\"/content/output\")[0]\n",
        "  op = Image.open(f\"/content/output/{op}\")\n",
        "  buffer = io.BytesIO()\n",
        "  op.save(buffer, 'png')\n",
        "  buffer.seek(0)\n",
        "  os.system(\"rm -rf /content/output/\")\n",
        "  return send_file(buffer, mimetype='image/gif')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Threading the flask app with ngrok\n",
        "\n",
        "from flask import Flask, request, send_file, jsonify\n",
        "from pyngrok import ngrok\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "import threading\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return jsonify(\"hello world\");\n",
        "\n",
        "@app.route(\"/api/transform\", methods=['POST'])\n",
        "def begin():\n",
        "  make_dir()\n",
        "  print(\"data recieved\")\n",
        "  cloth = request.files['cloth']\n",
        "  model = request.files['model']\n",
        "\n",
        "  cloth = Image.open(cloth.stream)\n",
        "  model = Image.open(model.stream)\n",
        "\n",
        "  cloth.save(\"/content/inputs/test/cloth/cloth.jpg\")\n",
        "  model.save(\"/content/inputs/test/image/model.jpg\")\n",
        "\n",
        "  # running script to compute the predictions\n",
        "  os.system(\"python /content/clothes-virtual-try-on/run.py\")\n",
        "\n",
        "  # loading output\n",
        "  op = os.listdir(\"/content/output\")[0]\n",
        "  op = Image.open(f\"/content/output/{op}\")\n",
        "  buffer = io.BytesIO()\n",
        "  op.save(buffer, 'png')\n",
        "  buffer.seek(0)\n",
        "  os.system(\"rm -rf /content/output/\")\n",
        "  return send_file(buffer, mimetype='image/gif')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup ngrok\n",
        "    public_url = ngrok.connect(3000)\n",
        "    print(\"Public URL:\", public_url)\n",
        "    threading.Thread(target=app.run, kwargs={\"port\": 3000}).start()"
      ],
      "metadata": {
        "id": "-SI-A2PB-tCT",
        "outputId": "bb314027-6b5c-478e-d6ff-0441d15ffc38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: http://4409-34-16-178-13.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:3000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether port is free or not\n",
        "import socket\n",
        "\n",
        "def check_port(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) != 0\n",
        "\n",
        "print(\"Is port 5000 free?\", check_port(5001))"
      ],
      "metadata": {
        "id": "aIDkpCha8A8S",
        "outputId": "1832be39-21e5-4428-b1dd-2ea1a9e1ee67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is port 5000 free? False\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8gqt11Y_RYxU"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}